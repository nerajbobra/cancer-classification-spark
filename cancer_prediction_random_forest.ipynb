{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Prediction with PySpark using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll walk through using PySpark to solve a classification problem. Specifically, we'll develop a random forest model to predict if a tumor is benign or malignant based on numerous numerical observations. \n",
    "\n",
    "This project will be utilizing Spark's ML library, which is designed to be used with DataFrame structures and utilizes pipelines to make things efficient and concise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some stuff first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import LongType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import sum\n",
    "from pyspark.sql.functions import array\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#the following lines allow the notebook to have multiple outputs for a single cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular dataset consists of 10 distinct measurements, such as radius of tumor, texture of tumor, etc. For each feature, there is a mean, standard error, and \"worst\" or largest value. To keep things simple, I've just grabbed the mean values of each measurement.  \n",
    "\n",
    "For more details on the dataset, visit this link:  \n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data  \n",
    "\n",
    "Note that I'm using PySpark with the databricks package to load csv data directly to a DataFrame. You should load the notebook with the following command:  \n",
    "PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" $SPARK_HOME/bin/pyspark --packages com.databricks:spark-csv_2.10:1.3.0  \n",
    "\n",
    "We'll also split the data into test/train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- diagnosis: string (nullable = true)\n",
      " |-- radius_mean: double (nullable = true)\n",
      " |-- texture_mean: double (nullable = true)\n",
      " |-- perimeter_mean: double (nullable = true)\n",
      " |-- area_mean: double (nullable = true)\n",
      " |-- smoothness_mean: double (nullable = true)\n",
      " |-- compactness_mean: double (nullable = true)\n",
      " |-- concavity_mean: double (nullable = true)\n",
      " |-- concave points_mean: double (nullable = true)\n",
      " |-- symmetry_mean: double (nullable = true)\n",
      " |-- fractal_dimension_mean: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  \n",
       "0         0.2419                 0.07871  \n",
       "1         0.1812                 0.05667  \n",
       "2         0.2069                 0.05999  \n",
       "3         0.2597                 0.09744  \n",
       "4         0.1809                 0.05883  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data as dataframe\n",
    "data = sqlContext.read.load('cancer.csv', format='com.databricks.spark.csv', header='true', inferSchema='true')\n",
    "\n",
    "#keep only the features with average values. don't keep id either\n",
    "data = data.select(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', \n",
    "                    'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', \n",
    "                    'fractal_dimension_mean'])\n",
    "\n",
    "#display the structure\n",
    "data.printSchema()\n",
    "\n",
    "#randomly split the data into a test/train set and validation set (80%/20%)\n",
    "splits = data.randomSplit([0.8, 0.2])\n",
    "data_train = splits[0]\n",
    "data_val = splits[1]\n",
    "\n",
    "#take a look at some data\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to deal with our label, diagnosis, which is a string. Use StringIndexer to convert string-based categorical features to a numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#convert diagnosis --> diagnosis_numeric. no one-hot encoding required because this can only have \n",
    "#two values (benign or malignant)\n",
    "stringIndexerDiagnosis = StringIndexer(inputCol='diagnosis', outputCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok, the next step is to combine all our features together into a feature vector. Note that there is no need to scale features here (ie, standardization is not required) as this is a tree based model. Call this feature vector \"features\", as the default name for the features vector for the random forest classifier is \"features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feats = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', \n",
    "             'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "assemblerAllFeatures = VectorAssembler(inputCols=all_feats, outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together everything we've done so far in a pipeline, and test the output on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09252</td>\n",
       "      <td>0.01364</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.07751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7.691, 25.44, 48.34, 170.4, 0.08668, 0.1199, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>7.729</td>\n",
       "      <td>25.49</td>\n",
       "      <td>47.98</td>\n",
       "      <td>178.8</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.07285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7.729, 25.49, 47.98, 178.8, 0.08098, 0.04878,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         B        7.691         25.44           48.34      170.4   \n",
       "1         B        7.729         25.49           47.98      178.8   \n",
       "2         B        7.760         24.54           47.92      181.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.08668           0.11990         0.09252              0.01364   \n",
       "1          0.08098           0.04878         0.00000              0.00000   \n",
       "2          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  label  \\\n",
       "0         0.2037                 0.07751    0.0   \n",
       "1         0.1870                 0.07285    0.0   \n",
       "2         0.1587                 0.05884    0.0   \n",
       "\n",
       "                                            features  \n",
       "0  [7.691, 25.44, 48.34, 170.4, 0.08668, 0.1199, ...  \n",
       "1  [7.729, 25.49, 47.98, 178.8, 0.08098, 0.04878,...  \n",
       "2  [7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pipeline\n",
    "pipeline = Pipeline(stages=[stringIndexerDiagnosis, assemblerAllFeatures])\n",
    "\n",
    "#fit the pipeline on the training data. what it means to \"fit\" the pipeline is to basically go through each of the \n",
    "#stages of the piepline and figure out the appropriate parameters. for example, in the stringIndexerDiagnosis stage, \n",
    "#it assigns benign=0 and malignant=1 (or vice versa)\n",
    "pipelineModel = pipeline.fit(data_train)\n",
    "\n",
    "#actually transform the data now that the pipeline is fit. note that the resultant features vector may be sparse\n",
    "output = pipelineModel.transform(data_train)\n",
    "\n",
    "#take a look at the output\n",
    "output.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally a good idea to take a look at the correlations between input features. This is a good first step at feature selection, in which we can remove any highly correlated (and therefore redundant) features. To do correlation analysis, select all the features and conver to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359657</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.987078</td>\n",
       "      <td>0.155305</td>\n",
       "      <td>0.500692</td>\n",
       "      <td>0.681405</td>\n",
       "      <td>0.818004</td>\n",
       "      <td>0.167295</td>\n",
       "      <td>-0.296278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.359657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364246</td>\n",
       "      <td>0.355019</td>\n",
       "      <td>-0.022673</td>\n",
       "      <td>0.244715</td>\n",
       "      <td>0.318619</td>\n",
       "      <td>0.317305</td>\n",
       "      <td>0.060946</td>\n",
       "      <td>-0.071381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.364246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986239</td>\n",
       "      <td>0.195223</td>\n",
       "      <td>0.553375</td>\n",
       "      <td>0.722670</td>\n",
       "      <td>0.848153</td>\n",
       "      <td>0.204963</td>\n",
       "      <td>-0.243678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0.987078</td>\n",
       "      <td>0.355019</td>\n",
       "      <td>0.986239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.493457</td>\n",
       "      <td>0.689762</td>\n",
       "      <td>0.817949</td>\n",
       "      <td>0.174611</td>\n",
       "      <td>-0.268104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.155305</td>\n",
       "      <td>-0.022673</td>\n",
       "      <td>0.195223</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>0.535203</td>\n",
       "      <td>0.557821</td>\n",
       "      <td>0.572308</td>\n",
       "      <td>0.613385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.500692</td>\n",
       "      <td>0.244715</td>\n",
       "      <td>0.553375</td>\n",
       "      <td>0.493457</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889785</td>\n",
       "      <td>0.838213</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>0.587738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.681405</td>\n",
       "      <td>0.318619</td>\n",
       "      <td>0.722670</td>\n",
       "      <td>0.689762</td>\n",
       "      <td>0.535203</td>\n",
       "      <td>0.889785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930081</td>\n",
       "      <td>0.538885</td>\n",
       "      <td>0.356105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0.818004</td>\n",
       "      <td>0.317305</td>\n",
       "      <td>0.848153</td>\n",
       "      <td>0.817949</td>\n",
       "      <td>0.557821</td>\n",
       "      <td>0.838213</td>\n",
       "      <td>0.930081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488991</td>\n",
       "      <td>0.197223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.167295</td>\n",
       "      <td>0.060946</td>\n",
       "      <td>0.204963</td>\n",
       "      <td>0.174611</td>\n",
       "      <td>0.572308</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>0.538885</td>\n",
       "      <td>0.488991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.296278</td>\n",
       "      <td>-0.071381</td>\n",
       "      <td>-0.243678</td>\n",
       "      <td>-0.268104</td>\n",
       "      <td>0.613385</td>\n",
       "      <td>0.587738</td>\n",
       "      <td>0.356105</td>\n",
       "      <td>0.197223</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "radius_mean                1.000000      0.359657        0.997695   0.987078   \n",
       "texture_mean               0.359657      1.000000        0.364246   0.355019   \n",
       "perimeter_mean             0.997695      0.364246        1.000000   0.986239   \n",
       "area_mean                  0.987078      0.355019        0.986239   1.000000   \n",
       "smoothness_mean            0.155305     -0.022673        0.195223   0.163579   \n",
       "compactness_mean           0.500692      0.244715        0.553375   0.493457   \n",
       "concavity_mean             0.681405      0.318619        0.722670   0.689762   \n",
       "concave points_mean        0.818004      0.317305        0.848153   0.817949   \n",
       "symmetry_mean              0.167295      0.060946        0.204963   0.174611   \n",
       "fractal_dimension_mean    -0.296278     -0.071381       -0.243678  -0.268104   \n",
       "\n",
       "                        smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "radius_mean                    0.155305          0.500692        0.681405   \n",
       "texture_mean                  -0.022673          0.244715        0.318619   \n",
       "perimeter_mean                 0.195223          0.553375        0.722670   \n",
       "area_mean                      0.163579          0.493457        0.689762   \n",
       "smoothness_mean                1.000000          0.676991        0.535203   \n",
       "compactness_mean               0.676991          1.000000        0.889785   \n",
       "concavity_mean                 0.535203          0.889785        1.000000   \n",
       "concave points_mean            0.557821          0.838213        0.930081   \n",
       "symmetry_mean                  0.572308          0.634319        0.538885   \n",
       "fractal_dimension_mean         0.613385          0.587738        0.356105   \n",
       "\n",
       "                        concave points_mean  symmetry_mean  \\\n",
       "radius_mean                        0.818004       0.167295   \n",
       "texture_mean                       0.317305       0.060946   \n",
       "perimeter_mean                     0.848153       0.204963   \n",
       "area_mean                          0.817949       0.174611   \n",
       "smoothness_mean                    0.557821       0.572308   \n",
       "compactness_mean                   0.838213       0.634319   \n",
       "concavity_mean                     0.930081       0.538885   \n",
       "concave points_mean                1.000000       0.488991   \n",
       "symmetry_mean                      0.488991       1.000000   \n",
       "fractal_dimension_mean             0.197223       0.510457   \n",
       "\n",
       "                        fractal_dimension_mean  \n",
       "radius_mean                          -0.296278  \n",
       "texture_mean                         -0.071381  \n",
       "perimeter_mean                       -0.243678  \n",
       "area_mean                            -0.268104  \n",
       "smoothness_mean                       0.613385  \n",
       "compactness_mean                      0.587738  \n",
       "concavity_mean                        0.356105  \n",
       "concave points_mean                   0.197223  \n",
       "symmetry_mean                         0.510457  \n",
       "fractal_dimension_mean                1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x101ca2850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAJsCAYAAADz8RV6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bc72910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#note: if the data set is large, you should limit the number of samples before converting to pandas\n",
    "cont_feats = data_train.select(all_feats).toPandas()\n",
    "\n",
    "#compute the correlation matrix\n",
    "corr = cont_feats.corr()\n",
    "print 'correlation matrix:'\n",
    "corr\n",
    "\n",
    "#plot the correlation matrix as a heatmap \n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, cmap=cmap, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that there are many highly correlated features. Looking across all the columns in each row of the heat map, the biggest offenders based are radius_mean, perimeter_mean, area_mean, concave points_mean, and concavity_mean. These features are highly correlated with multiple other features.  \n",
    "\n",
    "Let's update all_feats to exclude those features, and then take a look at the correlations again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022673</td>\n",
       "      <td>0.244715</td>\n",
       "      <td>0.060946</td>\n",
       "      <td>-0.071381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>-0.022673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>0.572308</td>\n",
       "      <td>0.613385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.244715</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>0.587738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.060946</td>\n",
       "      <td>0.572308</td>\n",
       "      <td>0.634319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.071381</td>\n",
       "      <td>0.613385</td>\n",
       "      <td>0.587738</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        texture_mean  smoothness_mean  compactness_mean  \\\n",
       "texture_mean                1.000000        -0.022673          0.244715   \n",
       "smoothness_mean            -0.022673         1.000000          0.676991   \n",
       "compactness_mean            0.244715         0.676991          1.000000   \n",
       "symmetry_mean               0.060946         0.572308          0.634319   \n",
       "fractal_dimension_mean     -0.071381         0.613385          0.587738   \n",
       "\n",
       "                        symmetry_mean  fractal_dimension_mean  \n",
       "texture_mean                 0.060946               -0.071381  \n",
       "smoothness_mean              0.572308                0.613385  \n",
       "compactness_mean             0.634319                0.587738  \n",
       "symmetry_mean                1.000000                0.510457  \n",
       "fractal_dimension_mean       0.510457                1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10bbc1ed0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAIxCAYAAAB6qn1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkiiy2JEmSKvr/oDHDMqx5Ij0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bc72310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#exclude the highly correlated features\n",
    "all_feats = ['texture_mean', 'smoothness_mean', 'compactness_mean',  'symmetry_mean', 'fractal_dimension_mean']\n",
    "cont_feats = data_train.select(all_feats).toPandas()\n",
    "\n",
    "#compute the correlation matrix\n",
    "corr = cont_feats.corr()\n",
    "print 'correlation matrix:'\n",
    "corr\n",
    "\n",
    "#plot the correlation matrix as a heatmap \n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, cmap=cmap, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks a lot better. There are still some correlated features, but much less so than originally.  \n",
    "\n",
    "Now, let's put everything together. Define a new feature assembler that only assembles the non-correlated features. Define a random forest classifier with default parameters, and put everything together in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#define a new assembler on only the non-correlated features\n",
    "assemblerAllFeatures = VectorAssembler(inputCols=all_feats, outputCol='features')\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#chain everything together into a pipeline\n",
    "pipeline = Pipeline(stages=[stringIndexerDiagnosis, assemblerAllFeatures, model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we didn't define any of the parameters for the random forest classifier. As it turns out, there are two parameters that need to be optimized: the max depth of the trees, and the number of trees in the random forest. To identify the optimal values for these parameters, use the CrossValidator.  \n",
    "\n",
    "I've set up the max depth to range from 1 to 10, and the number of trees to range from 5 to 70 in increments of 5. The metric used to determine the best performing model will be the area under the ROC, and the number of folds of cross validation are set to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a ParamGridBuilder to determine optimal values of elasticNetParam (range [0,1]) and regParam (typically \n",
    "#ranges between 0 and 1). we'll sweep through 0 to 1 in increments of 0.1 for both parameters\n",
    "paramGrid = ParamGridBuilder().addGrid(model.maxDepth, range(1,11)) \\\n",
    "                              .addGrid(model.numTrees, range(5,75,5)).build()\n",
    "\n",
    "#define the RMSE to be the evaluation metric for model performance\n",
    "evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "\n",
    "#set up 3-fold cross validation to determine the optimal depth parameter (this can be set higher for potentially \n",
    "#better results)\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "#do the actual cross validation on the training data\n",
    "CV_model = crossval.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CrossValidator iterated through every possible combination of maxDepth and numTrees, developed a model for each combination of values, and evaluated each model's performance based on the area under the ROC. The best performing model was saved and can now be accessed from the CV_model object. Let's take a closer look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trees: 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassificationModel (uid=dtc_59ddb99f004d) of depth 7 with 69 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_6057e4a41f15) of depth 7 with 77 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_fa2d9296e5a6) of depth 7 with 73 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_ae57c06defa3) of depth 7 with 63 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_23dbea96d070) of depth 7 with 63 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_c0d12ee7c54b) of depth 7 with 83 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_d43191e48a61) of depth 7 with 75 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_fb60dc3c7e57) of depth 7 with 67 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_b4ac7f569fee) of depth 7 with 81 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_bb12cd205749) of depth 7 with 67 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_8eddaf6774eb) of depth 7 with 61 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_25041af99c94) of depth 7 with 83 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_94878c0aaa66) of depth 7 with 71 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_53e01393d0d8) of depth 7 with 65 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_27b51e4394c0) of depth 7 with 77 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_a3f14e7d0765) of depth 7 with 85 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_9acda8045e84) of depth 7 with 71 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_a507bcd44d95) of depth 7 with 75 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_c12663eff115) of depth 7 with 79 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_2153dcff46dc) of depth 7 with 65 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_9f0ee8efc40c) of depth 7 with 65 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_142d373b97d9) of depth 7 with 59 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_52e9fb04cfd9) of depth 7 with 83 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_e59f7a67a9bd) of depth 7 with 75 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_cf2ab9ffa2d3) of depth 7 with 63 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_0e22ea78ae9f) of depth 7 with 69 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_07b24a6ae1c0) of depth 7 with 83 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_2f3e1dda4c3b) of depth 7 with 73 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_976f5537d71d) of depth 7 with 73 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_d51669a518b8) of depth 7 with 63 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_b2ddbb0104d7) of depth 7 with 77 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_aa2b5ca9b331) of depth 7 with 67 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_8e2065cdd69d) of depth 7 with 87 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_090448814dc2) of depth 7 with 83 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_f9d157794178) of depth 7 with 79 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_244bc654a571) of depth 7 with 73 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_bf7826ab784a) of depth 7 with 81 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_b9489bf90008) of depth 7 with 89 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_c565466779f0) of depth 7 with 75 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_80e66c42528a) of depth 7 with 83 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_a6495f125c0a) of depth 7 with 69 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_40b5bddee06d) of depth 7 with 77 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_53012f5c21f1) of depth 7 with 77 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_730526fb8714) of depth 7 with 67 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_7541f7a59360) of depth 7 with 67 nodes]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the best model\n",
    "best_model = CV_model.bestModel\n",
    "\n",
    "#for the best model, print out each tree in the random forest and list its depth and number of nodes\n",
    "print ('number of trees: %i') % (len(best_model.stages[-1].trees))\n",
    "best_model.stages[-1].trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we can see that the optimal max depth was identified to be 7 and the number of trees used was 45.  \n",
    "\n",
    "Ok, so now let's evaluate our model. We can define a UDF that gives us our prediction based on the probability score of the random forest. The random forest model outputs a column of type vector which is [probability_class0, probability_class1]. So we can just define a probability threshold and output a new column containing the threshold-based prediction.  \n",
    "\n",
    "We can also define some UDFs to calculate the true positives, true negatives, false positives, and false negatives. These will be used to calculate the precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a UDF that will take the prediction probabilities, and return the predicted class according to some \n",
    "#defined threshold. vector is defined as [probability_class0, probability_class1] where class0 is benign and \n",
    "#class1 is malignant. let's set our probability threshold to a simple value of 0.5 for now.\n",
    "prob_thresh = 0.5\n",
    "prediction_udf = udf(lambda vector: float(0. if vector[0] > prob_thresh else 1.), FloatType())\n",
    "\n",
    "#define UDF functions to calculate TP, TN, FP, FN\n",
    "TP_udf = udf(lambda arr: int(1 if int(arr[0]) == 1 and int(arr[1]) == 1 else 0), LongType())\n",
    "TN_udf = udf(lambda arr: int(1 if int(arr[0]) == 0 and int(arr[1]) == 0 else 0), LongType())\n",
    "FP_udf = udf(lambda arr: int(1 if int(arr[0]) == 0 and int(arr[1]) == 1 else 0), LongType())\n",
    "FN_udf = udf(lambda arr: int(1 if int(arr[0]) == 1 and int(arr[1]) == 0 else 0), LongType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the best model to our training data to see it's output probabilities. Let's then get our predictions based on a probability threshold of 0.5, and calculate precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09252</td>\n",
       "      <td>0.01364</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.07751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[25.44, 0.08668, 0.1199, 0.2037, 0.07751]</td>\n",
       "      <td>[39.0, 6.0]</td>\n",
       "      <td>[0.866666666667, 0.133333333333]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>7.729</td>\n",
       "      <td>25.49</td>\n",
       "      <td>47.98</td>\n",
       "      <td>178.8</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.07285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[25.49, 0.08098, 0.04878, 0.187, 0.07285]</td>\n",
       "      <td>[45.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[24.54, 0.05263, 0.04362, 0.1587, 0.05884]</td>\n",
       "      <td>[45.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         B        7.691         25.44           48.34      170.4   \n",
       "1         B        7.729         25.49           47.98      178.8   \n",
       "2         B        7.760         24.54           47.92      181.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.08668           0.11990         0.09252              0.01364   \n",
       "1          0.08098           0.04878         0.00000              0.00000   \n",
       "2          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  label  \\\n",
       "0         0.2037                 0.07751    0.0   \n",
       "1         0.1870                 0.07285    0.0   \n",
       "2         0.1587                 0.05884    0.0   \n",
       "\n",
       "                                     features rawPrediction  \\\n",
       "0   [25.44, 0.08668, 0.1199, 0.2037, 0.07751]   [39.0, 6.0]   \n",
       "1   [25.49, 0.08098, 0.04878, 0.187, 0.07285]   [45.0, 0.0]   \n",
       "2  [24.54, 0.05263, 0.04362, 0.1587, 0.05884]   [45.0, 0.0]   \n",
       "\n",
       "                        probability  prediction  TP  TN  FP  FN  \n",
       "0  [0.866666666667, 0.133333333333]         0.0   0   1   0   0  \n",
       "1                        [1.0, 0.0]         0.0   0   1   0   0  \n",
       "2                        [1.0, 0.0]         0.0   0   1   0   0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: precision = 0.993976, recall = 0.982143, F1 score = 0.988024\n"
     ]
    }
   ],
   "source": [
    "#run the training data through the pipeline, and then convert the prediction column\n",
    "#based on the prediction_udf\n",
    "train_results = best_model.transform(data_train)\n",
    "train_results = train_results.withColumn('prediction', prediction_udf(train_results.probability))\n",
    "\n",
    "#calculate the TP, TN, FP, FN as new columns\n",
    "train_results = train_results.withColumn('TP', TP_udf(array('label', 'prediction'))) \\\n",
    "                             .withColumn('TN', TN_udf(array('label', 'prediction'))) \\\n",
    "                             .withColumn('FP', FP_udf(array('label', 'prediction'))) \\\n",
    "                             .withColumn('FN', FN_udf(array('label', 'prediction')))\n",
    "train_results.limit(3).toPandas()\n",
    "\n",
    "#get the counts of TP, FN, FP\n",
    "TP_count = train_results.agg(sum(train_results.TP).alias('sum')).collect()[0].sum\n",
    "FN_count = train_results.agg(sum(train_results.FN).alias('sum')).collect()[0].sum\n",
    "FP_count = train_results.agg(sum(train_results.FP).alias('sum')).collect()[0].sum\n",
    "\n",
    "#calculate precision, recall, and F1 score\n",
    "precision = TP_count/float(TP_count + FP_count)\n",
    "recall = TP_count/float(TP_count + FN_count)\n",
    "F1_score = 2*precision*recall/(precision + recall)\n",
    "\n",
    "print ('training set: precision = %f, recall = %f, F1 score = %f') % (precision, recall, F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the results are pretty good. But let's take a minute to think about the problem we're trying to solve. We're trying to identify tumors as either benign or malignant. If we claim a tumor to be benign, but it's actually malignant, that could be a deadly mistake. So we'd like to impose the requirement of being very confident it's benign to report benign. This equates to setting the threshold for our prediction to a higher value, say 0.75.  \n",
    "\n",
    "How do we actually pick the right probability threshold? We can look at the precision and recall. In our case, we want a high recall and low precision. We can adjust our probability threshold until we see an increase in recall and a decrease in precision. Let's repeat the above process with a threshold value of 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: precision = 0.908108, recall = 1.000000, F1 score = 0.951841\n"
     ]
    }
   ],
   "source": [
    "#redefine our UDF for a probability threshold of 0.75\n",
    "prob_thresh = 0.75\n",
    "prediction_udf = udf(lambda vector: float(0. if vector[0] > prob_thresh else 1.), FloatType())\n",
    "\n",
    "#run the training data through the pipeline, and then convert the prediction column\n",
    "#based on the prediction_udf\n",
    "train_results = best_model.transform(data_train)\n",
    "train_results = train_results.withColumn('prediction', prediction_udf(train_results.probability))\n",
    "\n",
    "#calculate the TP, TN, FP, FN as new columns\n",
    "train_results = train_results.withColumn('TP', TP_udf(array('label', 'prediction'))) \\\n",
    "                             .withColumn('TN', TN_udf(array('label', 'prediction'))) \\\n",
    "                             .withColumn('FP', FP_udf(array('label', 'prediction'))) \\\n",
    "                             .withColumn('FN', FN_udf(array('label', 'prediction')))\n",
    "\n",
    "#get the counts of TP, FN, FP\n",
    "TP_count = train_results.agg(sum(train_results.TP).alias('sum')).collect()[0].sum\n",
    "FN_count = train_results.agg(sum(train_results.FN).alias('sum')).collect()[0].sum\n",
    "FP_count = train_results.agg(sum(train_results.FP).alias('sum')).collect()[0].sum\n",
    "\n",
    "#calculate precision, recall, and F1 score\n",
    "precision = TP_count/float(TP_count + FP_count)\n",
    "recall = TP_count/float(TP_count + FN_count)\n",
    "F1_score = 2*precision*recall/(precision + recall)\n",
    "\n",
    "print ('training set: precision = %f, recall = %f, F1 score = %f') % (precision, recall, F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 100% recall, and have dropped our precision to about 90%. Of course, there is a tradeoff. The overall accuracy, indicated by the F1 score, has dropped. But that's acceptable in this context, because we want to be on the safer side.  \n",
    "\n",
    "Let's run the analysis on the validation data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[13.43, 0.117, 0.07568, 0.193, 0.07818]</td>\n",
       "      <td>[45.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>8.878</td>\n",
       "      <td>15.49</td>\n",
       "      <td>56.74</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.08293</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.06621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[15.49, 0.08293, 0.07698, 0.193, 0.06621]</td>\n",
       "      <td>[45.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>9.000</td>\n",
       "      <td>14.40</td>\n",
       "      <td>56.36</td>\n",
       "      <td>246.3</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>0.03116</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.06833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[14.4, 0.07005, 0.03116, 0.1788, 0.06833]</td>\n",
       "      <td>[45.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         B        6.981         13.43           43.79      143.5   \n",
       "1         B        8.878         15.49           56.74      241.0   \n",
       "2         B        9.000         14.40           56.36      246.3   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11700           0.07568        0.000000             0.000000   \n",
       "1          0.08293           0.07698        0.047210             0.023810   \n",
       "2          0.07005           0.03116        0.003681             0.003472   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  label  \\\n",
       "0         0.1930                 0.07818    0.0   \n",
       "1         0.1930                 0.06621    0.0   \n",
       "2         0.1788                 0.06833    0.0   \n",
       "\n",
       "                                    features rawPrediction probability  \\\n",
       "0    [13.43, 0.117, 0.07568, 0.193, 0.07818]   [45.0, 0.0]  [1.0, 0.0]   \n",
       "1  [15.49, 0.08293, 0.07698, 0.193, 0.06621]   [45.0, 0.0]  [1.0, 0.0]   \n",
       "2  [14.4, 0.07005, 0.03116, 0.1788, 0.06833]   [45.0, 0.0]  [1.0, 0.0]   \n",
       "\n",
       "   prediction  TP  TN  FP  FN  \n",
       "0         0.0   0   1   0   0  \n",
       "1         0.0   0   1   0   0  \n",
       "2         0.0   0   1   0   0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: precision = 0.741379, recall = 0.977273, F1 score = 0.843137\n"
     ]
    }
   ],
   "source": [
    "#run the validation data through the pipeline, and then convert the prediction column\n",
    "#based on the prediction_udf\n",
    "val_results = best_model.transform(data_val)\n",
    "val_results = val_results.withColumn('prediction', prediction_udf(val_results.probability))\n",
    "\n",
    "#calculate the TP, TN, FP, FN as new columns\n",
    "val_results = val_results.withColumn('TP', TP_udf(array('label', 'prediction'))) \\\n",
    "                         .withColumn('TN', TN_udf(array('label', 'prediction'))) \\\n",
    "                         .withColumn('FP', FP_udf(array('label', 'prediction'))) \\\n",
    "                         .withColumn('FN', FN_udf(array('label', 'prediction')))\n",
    "val_results.limit(3).toPandas()\n",
    "\n",
    "#get the counts of TP, FN, FP\n",
    "TP_count = val_results.agg(sum(val_results.TP).alias('sum')).collect()[0].sum\n",
    "FN_count = val_results.agg(sum(val_results.FN).alias('sum')).collect()[0].sum\n",
    "FP_count = val_results.agg(sum(val_results.FP).alias('sum')).collect()[0].sum\n",
    "\n",
    "#calculate precision and recall\n",
    "precision = TP_count/float(TP_count + FP_count)\n",
    "recall = TP_count/float(TP_count + FN_count)\n",
    "F1_score = 2*precision*recall/(precision + recall)\n",
    "\n",
    "print ('training set: precision = %f, recall = %f, F1 score = %f') % (precision, recall, F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall remains high on the validation data, so this is good. Whenver we get new data that we want to evaluate, we can now simply apply the best model to it and get the results. You can save the best model here and load it at any later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#note that the below save function creates a folder called \"best_model_cancer\". if you call \"save\" again, you need\n",
    "#to first delete that folder.\n",
    "best_model.save('best_model_cancer')\n",
    "loaded_best_model = PipelineModel.load('best_model_cancer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
